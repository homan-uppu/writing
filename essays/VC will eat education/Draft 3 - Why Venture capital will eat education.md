Artificial intelligence is rapidly making knowledge work more creative by doing the less creative grunt work for us. While this shift enables us to create more than ever before, it also invalidates the core business model of education: paying money to learn.

Charging money in exchange for education only works when students have a reliable path to employment so that they can earn back their investment. But, as the creativity of our work increases, that reliability goes out the window **independent of the quality of the education program**. The fundamental nature of highly creative work doesn't allow for training people at scale reliably to be good enough at the skill, as I'll discuss below.

Outcomes for creative work follow the power law distribution: most results will are captured by a small set of top performers. The more powerful AI becomes, the more extreme this power law becomes. Therefore, the only viable business model for education will be venture capital: giving individuals capital to fund their learning, in exchange for equity in their outcomes.

In the age of intelligence, engineers, designers, analysts, product managers, researchers, and all the new roles that will be invented, will have to think like startup founders and raise money to fund their learning journeys, instead of paying to learn.

## No scalable, reliable way to train highly creative skills

First, let me clarify what I mean by creativity: the more creative a task is, the more ways there are to do it. From a game theory standpoint, creativity is proportional to the number of actions you can take, and the number of possible states you can end up in.

A worker on a factory line only has so many ways in which they can assemble something. It's not that creative. A content creator has nearly endless possibilities for a video. Highly creative.

A century ago, you could reliably train an able bodied person to work on a factory floor. With a few weeks or months of training and practice, most people who go through the training would become competent enough to earn money working at a factory.

Today, can we reliably train a large group of people to be able to make a living creating content? How many of them would become good enough? How long would it take them?

The more creative a skill is, the more variability there is in the outcomes of training, regardless of how good the training is. Even if Mr. Beast were to have a college for training creators, some may take off right away, some may take years to get good enough to generate a sustainable revenue, and most would probably give up at some point because it would take them too long.

Even at Ycombinator, the world's most successful startup accelerator, the majority of the startups fail. There is no school for business in which the majority of graduates build a sustainable business. Most authors, filmmakers, content creators, entrepreneurs fail. Even those that have the best resources available to them (e.g. children of already successful creatives) may never become good enough!

Why is this the case? I think it's because the more creative the skill, the more it relies on intuition that manifests through taste (https://paulgraham.com/goodtaste.html) and judgement (https://nav.al/judgment). The less creative it a skill is, the more it relies on following rules and guidelines. The latter can be trained for reliably. Training intuition can't be done directly. You can't read all the books there are on entrepreneurship and be able to build a great company. Training intuition happens indirectly: by doing, through inspiration, through personalized feedback at the right time from the right people. And even when all of those boxes are ticked, some peoples' intuitions may take very long to get good enough, and many never get good enough, for reasons that are difficult to explain, and would take an entire essay to explore in reasonable depth.

Now perhaps there can be a training program that can reliably train people to be good enough for highly creative skills, such that the majority that go through the course will be good enough to make a living from that skill within 4 - 6 years, which would enable them to pay for the course. Even if it's somehow theoretically possible, we haven't found one yet, so at the very least we should be able to agree that this it would be a monumental challenge to reliably train for highly creative skills.
## All knowledge work will become highly creative

AI will make all knowledge work similarly highly creative, making training for it lose its reliability, and thus invalidating paying to learn these skills as most who pay won't recoup their investment.

To see why, let's look at a specific example: the software engineer. I'm choosing this because computer science is the fastest growing major, and most people studying computer science do so in order to become software engineers (as of today), so it's a good starting point for analysis. And I believe the lessons we learn studying software engineers will apply to other knowledge work.

In the mid 2010's, I would say that you could reliably train software engineers to be good enough to land great jobs in the world. While the best engineers were incredibly creative, and competent, and oftentimes an order of magnitude better than the average, there was still a lot of room for the average to contribute and grow within companies.

The average had room because someone still had to do the low creativity work of implementing things. And anyone who has ever written software pre AI knows just how much grunt work goes into translating a great idea on paper into an actual working breathing application.

But what would happen when AI can do most of that grunt work? Then, an engineer would focus on higher level decision making: architecture, system design, and perhaps product decisions. And they'd only drop into lower levels of abstractions when AI fails.

Pushing it even further: what would happen when AI can translate a spec and design references into features reliably; when a software engineer can command and instruct intelligent, instantaneous, always available teammates to do most of the engineering? The engineer would become a sort of mini CEO within the company: obsessing over what products / business lines to build, how to serve customers best, while diving deep into the code when the AI fails. In fact, many of the best "engineers" at the fastest growing startups already operate in this way as they aggressively push current generation AI to build for them.

As AI improves, software engineering turned becomes a role that looks awfully similar to an entrepreneur. It becomes highly creative.

We can how a similar evolution would happen for any role. Designers who would spend a lot of time tweaking design files in Figma would similarly spend a lot more time on the brand, understanding customers, and how the product would evolve to serve their needs better.
## The power law

There's one more feature of highly creative work: outcomes follow the power law distribution: most results are captured by a small percentage of creators.

We've seen this across the board in creative domains:

- (andrew chen's image).
- (mobile app downloads)
- (companies - Peter Thiel quote).

The more creative the skill is (i.e. the more complex the task is), the more extreme the power law distribution of outcomes: the top capture an even greater percentage of outcomes.

As AI improves and makes knowledge work more creative, we will similarly find that the best are orders of magnitudes better than the average.

We can already see this happening right now. After AI started helping us code, some software engineers that had a knack for picking it up and using it well, got insanely better than the rest of us. I don't think most people realize just how good the best engineers today are that are highly leveraged by the latest AI models (GPT-4 / Claude 3.5 Sonnet).

While I don't think that distribution of ability in knowledge work is close to that of highly creative skills such as entrepreneurship, it's getting much closer.

When the best engineers become many, many orders of magnitude better than the average, they will similarly capture most of the value in the market. We're seeing early signs of this today. There are countless new grads and junior software engineers struggling to get jobs, or even land interview, while simultaneously there exists an insatiable demand for great engineering talent with never-before-seen sky high compensations.

Many of the top startups no longer have new grad / internship positions because they've realized that training "up" someone average doesn't work as the skill has become a lot more creative. The ones getting hired are already incredibly skilled having honed their craft building their own projects.

Studying startups is a great way to get a glimpse of the future because they are often indicative of how the rest of the market will behave a few years down the line. The market has started to bake in the new reality of the increased power law distribution of skills for software engineering and other knowledge work roles.

As this trend amplifies, the majority of graduates will struggle very hard to get a return on their investments on education. Any student considering taking out a loan to pay for an education should strongly reconsider.

## How I see it playing out

The greatest "ed-tech" company won't even be seen as one. It'll be the one that can build and scale this way of investing in individuals.