https://claude.ai/chat/0931856e-3a1c-4686-b4a9-e3c80fd46323

at this point, i'm not sure if it's just bending itself to my will, or whether the point i made is actually legit.

---

this can be expanded: a truth seeking agent will push back hard if it believes your point isn't aligned with what it believes is the truth, and you should not be able to bend it to your will by just nudging it with questions... makes me trust its opinions less. interesting: the same thing happens with humans! 