### Intro

Millions of young people are facing a bleak reality: that what they’ve learned is useless, and that they’re not going to be able to repay the loans they took out for their education anytime soon, if ever. Billions are in the pipeline to arrive at the same unfortunate destination. 

Artificial intelligence has accelerated the gap between how students are trained, and what the world needs from them, and has also invalidated the fundamental business model that powers education: selling education as a product that students (its customers) pay for.

Unfortunately, throwing more money at universities or even making education free does not solve these problems. We need a new education system for a post-AI world with a fundamentally different business model and set of incentives. This essay is my exploration of what this future looks like and how we can build it.

Education is inextricably linked to what the economy wants. Most students want to learn skills that enable them to create value in the world. This desire to create value for others will continue to exist no matter how good AI becomes - it’s a deep evolutionary conditioning. We have to work backwards from first understanding what the world wants from us in a post-AI world, to then figuring out what the right education looks like and how to deliver it at scale.

### AI makes the economy extreme

AI makes our economy extreme in which the majority of value is created by a minority. The more powerful AI becomes the more extreme the world becomes: value creation becomes further concentrated in the hands of few. The more extreme the economy becomes the less room there is for the average. There is no middle class in an extreme economy because the middle class is made up of average (by definition).

To understand why AI makes our economy more extreme we need to understand the relationship between complexity of a task and its outcomes.  

Simple tasks have more equal outcomes. For example, 100 factory workers assembling the same product will not have that much variance in their output. Complex tasks on the other hand have very extreme outcomes in which a few individuals account for the major majority of the economic value created. For example, if we take 1 billion YouTube content creators, a tiny fraction of them will generate the majority of the revenue on the platform. And we see such extreme outcomes in any complex task such as building companies, making music, etc.

AI makes our work more complex by doing the simpler work for us. The more powerful AI becomes, the more complex our work becomes, and thus the more extreme outcomes become.

We can see how AI makes work more complex by looking at what’s happening to software engineering. AI is on track to being able to produce the majority of code that will be written. Today, for someone to become a great engineer, they will have to contribute a lot more than just code. (to do continue this later).

There is an underlying hierarchy of complexity. How do I know that design, strategy, and higher level architecture decisions are more complex than implementing requirements? Because they have always had much more extreme outcomes. given the relatively lower complexity of software engineering over the past couple of decades the variance between engineers on most teams was seldom more than a factor of 20 or 30 (of course there have been exceptional engineers that contributed far more but if you study what they’re done, you will notice that much of their value addition came outside of just engineering and how to deal with choosing the right problems to work on as well). But for designers and founders, the outcomes have always been quite extreme, and therefore on average we can deduce that software engineering has been a simpler skill than design, etc..

As all knowledge work becomes highly complex we will find extreme outcomes in all kinds of work.

A common claim is that AI will create more jobs than it takes. While this is true, it ignores the fact that the work it creates will be far more complex, making it extremely difficult to do it well enough to consistently earn a living from it - in the same way that it is very difficult to make a living from art, startups, music, etc. Those that do well will do exceptionally well, but most will not. AI enables more opportunities than ever before to create value, but each opportunity will be far more difficult to capitalize on for most.

How extreme will the economy become? It’s proportional to how powerful AI becomes: the more powerful AI becomes, the more value creation is concentrated at the top because the more leverage the best have to outcompete everyone else. 

For example, in a couple of years its entirely possible that the best programmer can help train a model that anyone can use that accurately encapsulates 70 - 80% of their skill and sell their intelligence as a service for anyone else to use at a fraction of the cost of hiring an engineer. In such a world, it’s difficult to see space for more than a handful of exceptional programmers. In a few years once AI is embodied and can manipulate the real world, a great Biryani chef from Afghanistan could train an AI to reproduce the best possible biryani that anyone anywhere can consume… it’s difficult to see how there can be more than a handful of top biryani chefs that serve the entire world.

The more powerful AI becomes, the less room there is for the average. You must be one of the best at what you do. Excellence is quickly becoming a necessity. The more powerful AI becomes, and the more the economy grows, the more extreme the upsides become. In a couple of decades we may very well see individuals create trillions of dollars of value just by themselves.

### What the economy wants

In a highly complex, extreme world, there are two levers that individuals can pull to find their way towards being able to create value:

1. Differentiation: offer something that few others can.
2. Excellence: be one of the best at what you offer.   

The more similar you are to others, the stiffer the competition you face, and the more difficult it is to be one of the best. You can escape such competition through differentiation. But, no matter how much you can differentiate, you will likely still come across competition - proportional to how lucrative that skill is - and you will have no choice but to strive for excellence in that thing in order to be able to create any value.

In a post-AI world, there will be a great pressure on humanity to run a much wider range of experiments that simply weren’t possible without the leverage AI provides. For example, a few decades ago, to make a movie you needed to have access to a great deal of resources, and it took many people to produce a single film. Technology has drastically reduces the barrier for an individual to make a video and publish it to the world, leading to a great pressure to differentiate yourself and create the kind of videos that no one else is doing because the act of creation itself is much easier. Similarly, AI will drastically increase the range of human activities. In fact, the roles that we have today: chemist, physicist, biologist, software engineer, marketer, etc. likely won’t make much sense as each individual’s role will be so fluid and unlabelable as there may only be a few others in the world doing what they do.

But isn't the world a positive-sum game, meaning there should be room for everyone to create value without competition - each offering something so unique that no one else can? In theory, this may be possible. This is sort of the North Star - the final state of the economy that we work towards, but in reality this will be very difficult to achieve simply because it's not easy for someone to discover their unique capabilities. It takes time and many will never do so before they die, and thus will find themselves competing. Similarly, an individual's uniqueness may not be valued by the world (e.g. someone who's innately fascinated by studying poisonous mushrooms) and they will find it difficult to create enough value, and will be forced to compete on a more lucrative skill. It will be difficult to completely avoid competition. And lastly, it may be the case that multiple individauls are naturally inclined to express themselves in similar ways and will thus find themselves in a competition (though I doubt this is the case since I believe that each individual is far more unique than we think, but I could be wrong).

You may read this and feel that this is how the economy has always worked, and you would be somewhat right: these are the dynamics you'll find at the pinnacle of any field: arts, entrepreneurship, academics, etc. But, what makes this such a massive paradigm shift today is that it applies to everyone, not just those at the top of their game.

### Cost of education will skyrocket

Many believe that AI will provide quality education at scale, cheaply. This is true to an extent: each individual will soon have access to a personal tutor that can guide them through humanity’s knowledge according to their unique temperament, inclinations and pace. But, this will also mean that the cost for the kind of education that AI cannot provide: the personalized guidance & feedback from masters of their crafts will skyrocket.

Until and unless AI can outcompete humans in every single human endeavor from arts to science to anything, there will continue to exist quality teachers who will be able to improve a student's chance for success to some degree through training that the best AIs cannot provide.

The more complex our work becomes, the more scarce are the teachers who can actually, meaningfully, impact a student's outcomes.

To see why we have to understand the nature of becoming excellent at a highly complex skill vs. a simple skill. Training simple skills is relatively straightforward: by putting students through a predetermined curriculum, they will get good enough with sufficient time. For example: you can reliably train a hundred people to effectively assemble a product on a factory line given enough time (say a few months or years). Similarly, teaching someone the syntax of a programming language, or how to use spreadsheets can be done reliably because these are not complex skills. The simpler the skill, the more teachers can teach the skill.

Getting great at highly complex skills is incredibly difficult because even with great training, many will fail. Most graduates from the best music programs, filmmaking schools, content creator courses, and even top startup accelerators fail. The more complex the skill, the less you can become proficient by simply learning a methodology / rules / a way of doing something, you must develop skills such as intuition (having an innate sense for what to do), taste (an understanding of what is high quality) and great judgement (making the right decisions).

Those who are capable of effectively teaching / mentoring for highly complex skills are rare, and their time is worth far more than what most students can pay for because outcomes are extreme, successes are larger, and therefore the value of increasing the chance of success by even a small factor is incredibly valuable. For example, a teacher who can improve someone’s chances of building a successful startup, or creating viral content by even 5% would be able to earn millions on the market, why would they teach for any less?

The demand for great teachers will also skyrocket because the value of improving chances of success by even a small percentage is much more valuable when success leads to an extremely high outcome. 

The converse is also true: in a post-AI world, a teacher willing to teach for something a student can afford to pay for is almost certainly not a good enough teacher who will not be able to impact the student’s outcomes at all. (Ofc there will be exceptions: great teachers who mentor students out of the desire to give back and sacrifice creating a lot of wealth in the process, but such individuals are so rare that they don't impact my argument at all). Even worse: the average teacher will likely do more harm than help because they themselves won’t understand what it takes to be one of the best at a complex skill, and hence they’ll likely teach bad habits, and impart the wrong model of how the world works.

Another thing to recognize is that time is of the essence for a student who wants to be successful - perhaps more so than ever before. The sooner a student discovers their unique talents, and the more training they put in to become excellent at it, the more likely they are to succeed. Any delay in this learning process can put them slightly below the top - which, as the world becomes more extreme, will not be enough to create value. Therefore, spending time with the wrong teacher can completely derail a student with great potential.

### Education’s business model is broken

The business model of selling education as a product that students (customers) pay for is being attacked on two fronts:

1. The more extreme outcomes become (follow a power law distribution), the more students will not be able to earn back their investment in education anytime soon, if ever, making paying for education too risky.
2. The more complex our work becomes, the more expensive the right teachers become - making quality education unaffordable even for those who can pay today’s tuition.

Making education free doesn’t work because the teachers who can meaningfully impact a student’s outcomes will become far too expensive to hire, meaning those that public institutions (backed with taxpayer money) can afford to hire will almost certainly be the wrong teachers who will likely do far more harm than help. Of course many countries in the world will probably still run this experiment of free education only to realize that many of their citizens who went through those programs will fail to create value in the world.

We need a new system that incentivizes the best teachers to teach, and to enable students to access the best teachers without having to pay for it (as they will not be able to afford it). Without such a system, opportunity will be further concentrated in the hands of those with extreme wealth who can afford directly paying the best teachers for their time, while those who don’t have such wealth will be severely disadvantaged in ways that they weren’t before.

In a post-AI world, venture capital is the only viable business model for education. Venture capital is a form of financing popular in the startup world in which investors give startups money in exchange for equity in the company itself. Venture capital works exceptionally well in domains with extreme outcomes (that follow the power law distribution) because an investor only needs a few of their investments to become successful to more than make up for the many failed investments they will inevitably have.

But venture capital only applies to companies, how would venture capital work for students? Let’s assume we have a new kind of financial instrument (let’s call it a “personal token”) that represents an individual’s equities in companies and other assets that they will accumulate throughout their career. Let’s say this personal token can be divided into shares and sold to investors such that the investors gain equity in wealth that the owner of a personal token will create throughout their lives.

For example: Alice - a promising young designer - sells 3% of equity in her personal token to investors for $100k. As Alice accumulates equities in companies by working at them (or starting them), the value of Alice’s personal token increases, thereby increasing the value of the equities that her investors hold in her personal token. In an extreme, post-AI world, if Alice goes onto becoming successful, it’s very likely the wealth she will create will be very, very high, and thus she would provide ample returns to her investors.

In the context of education: instead of charging students money to train them, the best teachers (who are capable of meaningfully impacting a student’s outcomes for highly complex skills) would instead pay students to train them in exchange for equity in their personal token. 

From the perspective of teachers: 

1. This is the only way to financially attract the best teachers because their value on the market is too high for any student to be able to pay them up front. Equity in a student’s upside works because in an extreme world, the successful students will earn a lot - a lot more than what the teacher invests in them.
2. They have skin in the game: they are incentivized to help the student succeed and are penalized if their student does not succeed (by losing the money & time they invested in the student).

From the perspective of students: instead of paying money, they are instead paid to learn. It’s not enough to make education free because students need to pay to live in the right places for their crafts, and also for potentially expensive tools that enable them to do great work. By raising capital through personal tokens, students share risk with investors instead of bearing everything themselves - which, in a post-AI world, will likely lead to crippling debt.

### A new education system

Education has many valuable components of which training / mentorship is just one of them. In my view, education must help with:

1. Discovery: enabling a student to discover their unique talents, their natural strengths.
2. Training: enabling a student to become excellent at their craft.    
3. Credentialing: successful graduates are “stamped” such that the world values them for graduating even before they may do great work. In a world with so much noice, signaling competence is incredibly valuable for students to enable them to access resources and connect with the right people easily.
4. Community: ambitious, highly motivated, set of peers is invaluable. Most valuable learning happens through osmosis with the right peers.

These features of education go hand in hand, and I believe all of them are very important.

Personal tokens enable a wider range of possible configurations of these components for students. There will be scouts who specialize in discovering what individuals’ strengths are. There will be many teachers who will help students excel at a certain capability.

Students will be able to mix and match teachers to help them achieve what they want. For example, a young student interested in building products would probably want a teacher (investor) who’s excellent at marketing and selling, and perhaps another who is a master designer, and perhaps one more who has already built a product / company in the domain that this student is interested, who will be able to guide them through the specific nuances of that domain.

For students, their list of shareholders in their personal token will be the most powerful credential. If a young, promising designer is invested by, say, Jony Ive because he believes in the student’s potential, the world will take notice. Such a signal will be much more powerful than, say, graduating from Stanford because Jony had to actually put his money on the line - which he is unlikely to do unless he actually believes in the student’s potential. Of course, no matter the credential, an individual eventually has to create value in the world to be held in high regard - credentials don’t have an infinite lifespan.

Teachers may band together to form “guilds” that resemble startup accelerators. They choose which students to invest in together and build a community such that students can learn with others. The range of such guilds and the kind of skills they may train will be so large that we won’t be able to predict. A guild for making a certain kind of food that produces the top chefs for that food who train AI to scale their unique recipes to the world, or a guild for creating certain kinds of creative furniture, homes, products, scientific research, and many other skills and activities that haven’t been invented yet.

I cannot imagine a better way to train for the range of possibilities of human expression that AI will enable than a sort of “free market” of education options financed by venture capital through personal tokens (or whatever they will be called).

Need a para here that outlines the concerns and how to address them: i.e. preventing harassment, abuse, etc.

### The fall of traditional education

As AI becomes more powerful, and the world becomes more extreme, with less room for the average, legacy education institutions (and by extension ANY program that charges students money to teach) will fail because:

1. They can’t attract / retain teachers who are competent enough to meaningfully impact a student’s outcomes - as the value of such a teaching skill will become astronomically high.
2. They will not adapt to changing needs quickly enough because they don’t have direct skin in the game: they continue to generate revenue from students even if those students go onto fail.
    
Eventually, the value of their credentials will deteriorate as reality catches up and the world sees that their credential is no longer a valuable signal of competence.

What will happen to legacy institutions will be similar to what happened to big publishers after social media took off: they may continue to exist, but as everyone gained the power to publish their thoughts and news from their perspective online, big publishers became shells of themselves. There was a time when everyone in the US consumed their news from a handful of big publishers, whereas today each individual consumes information from a large marketplace of options, covering a wide range of topics, from creators of all sizes.

Similarly, through personal tokens, we will see a large marketplace of options for education that each individual can pick and choose their learning path, their teachers, etc. Such a marketplace enables a much wider range of possibilities of education.

It pains me as I've come to the realization that the world will be slow to adapt to these changes. Everywhere around me I see young people falling into traps that will be hard to climb out of. A family selling their home to pay for their child's mid-tier college tuition that I know will be near-useless. Many young people persuaded to learn skills in ways that will be useless - by those who thrived in a pre-AI world in which such skills may have been useful, but are now worthless. It fucking hurts. They're going to feel a world of pain. And it hurts me more that there are people with incredible potentials that will wither away - broken down by an education system that simply no longer works in today's world.

College admissions officers have gone insane due to their insulation from reality - they have no incentive to admit students with potential. The best colleges in the US are filthy rich and will not run out of their endowments anytime soon. They can admit whoever they want, according to whatever admissions criteria they have. 

Colleges have acted as faulty gatekeepers: routinely pass up great talents due to admissions officers with no skin in the game, who have literally gone insane due to their insulation from reality, who care more about optics than actual potential that can change the world. There are so [many](https://x.com/allgarbled/status/1907430185827471858) [cases](https://x.com/deedydas/status/1906898551273337209) that make my blood boil where gems of individuals are passed up for the dumbest of reasons. If such individuals could raise capital through personal tokens, they would have some of the greatest minds backing them, yet they are unfortunately optimizing to be recognized by outdated, legacy institutions who’s credentials and training will become quickly useless in a post-AI world.

In my eyes, not watering a seed that has the potential to grow into a tree that provides shade and nourishment to many is as much of a sin as chopping one down. Legacy education is incredibly oppressive - especially for those with the greatest potential to change the world for the better.

We desperately need a better solution. Fortunately, AI invalidates the foundational business model of the old system, ushering us into a new education system that better democratizes opportunity.

### What about the average?

There are 2 kinds of average: those who are genuinely average and will likely never be able to contribute to the economy no matter how much work they do, and another kind that has great potential, but simply hasn’t tapped into it yet, and therefore is passed up by all investors.

We will absolutely need some kind of universal basic income, I don’t see a way around this.

For the latter group: those with potential, unlike traditional education institutes, teachers have a strong incentive to scale their teaching to the world without holding anything back because the better they can teach people before they even invest in them, the more strong their top-of-the-funnel becomes because more students are willing to go to the teachers that have already taught them through their content (and soon: their AI agents they train to teach in their way). (todo: show the PG example here - which is a great example for how YC’s early students came to them).

Unfortunately, I think life will be difficult for the former group. I do think we will achieve basic income at some point (as there is no other way), but I also believe that such income will never feel “enough” - especially as the world races to create more than we have ever created: great new products and experiences will likely be very expensive when first launched.

### Timeline


### Notes

- (there are other factors at play here that determine extreme outcomes such as: freedom of expression, and ease of distribution, etc. but those factors are on track to become “better” along with AI).
- Are extreme outcomes inevitable? In a hypothetical world with equal opportunity with incredibly powerful AI to turn ideas into reality and quickly distribute to the world, outcomes will be very extreme: a small number of individuals will create the majority of economic value in the world. Extreme outcomes is a feature of a fair and highly creative society. Our problem isn’t extreme outcomes. It’s an insufficient, median outcome and unequal opportunity (lack of mobility). Unfortunately, much of political discussion these days is mistaken about what the problem actually is. Societies that believe that unequal outcomes is the problem to solve will have no choice but to regulate use of technology and freedom of expression (to preserve simpler work with less extreme outcomes) or to redistribute wealth so aggressively that will drive out those with the talent to create extreme outcomes. Such societies will stagnate. We need a way to enable equal opportunity, which, of course includes ensuring that people have enough to survive well enough, even if they’re unable to make a living by creating value in the world.

### Self notes

- Hierarchy of complexity is super important. Perhaps you can include it in the appendix - e.g. the comparison between Chess and Go.
- Differentiation: show the visual that you have in your mind - how leverage incentivizes differentiation.
- There is a very important point here that describes that the range of valuable experiments increases proportional to leverage. This is actually critically important to justify personal tokens - because you need a “free market” of education to be able to find and capitalize on the opportunities that AI enables.